# Adjust the import as necessary
import os
import logging
import PIL.Image
from typing import Any
from langchain.chains.summarize import load_summarize_chain
from langchain.docstore.document import Document
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
# Configure logging
logging.basicConfig(level=logging.DEBUG)

# Set the user agent
os.environ["USER_AGENT"] = "myagent"


def docs_to_str(docs: list[Document]) -> str:
    return "\n".join([doc.page_content for doc in docs])


def generate_twitter_post(input_text: str) -> str:
    '''
    Generate a Twitter post using the Google Generative AI model.
    '''
    model = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0.5,
        max_tokens=None,
        timeout=None,
        max_retries=2,
    )

    prompt_template = """
Rewrite the entire article to make it suitable for a Twitter post that is eye-catching, includes hashtags, and uses Taiwanese expressions for a local touch.
"{text}"

# Steps

1. **Summarize Key Points**: Extract the main idea or message of the article. Condense it into one or two short, engaging sentences that fit Twitter's character limit (280 characters).
2. **Use Taiwanese Expressions**: Adapt the language of the tweet to incorporate local Taiwanese phrases or vocabulary to appeal to the Taiwanese audience.
3. **Add Hashtags**: Include 2-5 relevant hashtags to broaden reach and catch the attention of potential readers. The hashtags should be related to the article's subject matter and written in a Taiwanese conversational style.
4. **Include a Hook**: Write a compelling opening to immediately grab attention. This might be a question, a surprising fact, or a striking opinion drawn from the article.
5. **CTA (Call to Action)**: Add a prompt encouraging interaction or clicking on the link, such as "é»žæˆ‘çœ‹æ›´å¤šå–”" (Click here for more) or "ä½ æ€Žéº¼çœ‹å‘¢ï¼Ÿ" (What do you think?).
6. **Link to Article** (Optional): Include a shortened link to the original article where needed.

# Output Format

- One or two concise tweets.
- Each tweet must be 280 characters or less.
- Incorporate local Taiwanese phrases where appropriate.
- Include 2-5 relevant hashtags.
- Include a call to action to encourage engagement.

# Examples

**Input**:
An article discussing the impact of digital detox on productivity.

**Output**:
"æœ€è¿‘è¦ºå¾—ç§‘æŠ€è®“ä½ æŠ“ç‹‚å—Žï¼Ÿè©¦è‘—ä¾†å€‹æ•¸ä½æŽ’æ¯’å§ðŸ“µï¼Œä¹Ÿè¨±èƒ½å¹«ä½ æ‰¾å›žå°ˆæ³¨åŠ›è·Ÿç”Ÿæ´»çš„å¹³è¡¡ #æ•¸ä½æŽ’æ¯’ #é›†ä¸­æ³¨æ„åŠ› #ç”Ÿæ´»æ…‹åº¦ é»žæˆ‘çœ‹æ›´å¤šå–”: [link]"

**Input**:
An article exploring the benefits of adopting renewable energy.

**Output**:
"å°ç£çš„æœªä¾†å°±æ˜¯è¦ç¶ èƒ½ï¼ç”¨å¤ªé™½èƒ½ä¸ä½†ç’°ä¿é‚„å¯ä»¥çœè·åŒ…ðŸ’°ã€‚å¤§å®¶ä¸€èµ·æŠ•å…¥ç¶ è‰²è¡Œå‹•å§ï¼#å†ç”Ÿèƒ½æº #æ¸›ç¢³ #ç¶ èƒ½ç”Ÿæ´» ðŸŒ± è¨˜å¾—ä¾†çœ‹çœ‹å–”: [link]"

# Notes

- Make sure each tweet is engaging and uses expressions familiar to a Taiwanese audience.
- Hashtags should be popular and relevant, and written in a way that resonates locally.
- Tweets should be easy for readers to grasp and encourage sharing.
"""
    prompt = PromptTemplate.from_template(prompt_template)

    chain = prompt | model
    tweet = chain.invoke(
        {"text": input_text})
    return tweet.content


def generate_slack_post(input_text: str) -> str:
    '''
    Generate a Slack post using the Google Generative AI model.
    '''
    model = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0.5,
        max_tokens=None,
        timeout=None,
        max_retries=2,
    )

    prompt_template = """
å°‡æä¾›çš„æ–‡ç« æ‘˜è¦è½‰åŒ–ç‚ºé©åˆ Slack ä¸Šå®£å‚³çš„æ ¼å¼ï¼Œä½¿å…¶æ›´å¸å¼•äººä¸¦é¼“å‹µè®€è€…é»žæ“Šã€‚è«‹ä½¿ç”¨å°ç£åœ°å€å¸¸ç”¨çš„è¡¨é”æ–¹å¼ï¼Œä¸¦åŠ å…¥ Slack è¡¨æƒ…ç¬¦è™Ÿä¾†å¢žåŠ è¶£å‘³æ€§å’Œå¸å¼•åŠ›ã€‚
"{text}"

# æ­¥é©Ÿ [é¸å¡«]
- é‹ç”¨æ¢åˆ—å¼åˆ—å‡ºé—œéµé‡é»žï¼Œä¿æŒç°¡æ½”æœ‰åŠ›ã€‚
- åŠ å…¥ Slack çš„ emoji è¡¨ç¾æƒ…æ„Ÿï¼Œä¾‹å¦‚ðŸ”¥ã€ðŸ‘‰ã€ðŸ’¡ç­‰ã€‚

# Steps [optional]

1. å°‡æä¾›çš„æ–‡ç« æ‘˜è¦ä¸­çš„ä¸»è¦é‡é»žæå–å‡ºä¾†ã€‚
2. é‡æ–°çµ„ç¹”æ‘˜è¦ï¼Œä»¥æ¸…æ™°çš„æ¢åˆ—å¼å‘ˆç¾ã€‚
3. é‹ç”¨å°ç£ç”¨èªžï¼Œä½¿å…§å®¹æ›´å…·æœ‰è¦ªåˆ‡æ„Ÿå’ŒæŽ¥åœ°æ°£ã€‚
4. åŠ å…¥ Slack emoji ä»¥å¢žå¼·è¶£å‘³æ€§å’Œå¸å¼•åŠ›ï¼Œä¸¦å¸å¼•è®€è€…é€²ä¸€æ­¥é»žæ“Šã€‚

# Output Format

- æ‘˜è¦æ‡‰æŽ¡ç”¨æ¢åˆ—å¼æ ¼å¼ã€‚
- æ¨™é»žç¬¦è™Ÿå’Œ Emoji éœ€è¦å¹³è¡¡ä½¿ç”¨ï¼Œä»¥å¢žåŠ è¶£å‘³ä½†ä¸éŽåº¦ã€‚
- ä½¿ç”¨å°ç£å¸¸è¦‹ç”¨èªžï¼Œè®“è®€è€…æ„Ÿåˆ°è¦ªåˆ‡ä¸¦å¢žåŠ å…±é³´ã€‚

# Example

**è¼¸å…¥æ–‡ç« æ‘˜è¦ï¼š**  
ã€Œéš¨è‘—ç–«æƒ…çµæŸï¼Œä¼æ¥­å°æ–¼æ··åˆå¼å·¥ä½œçš„éœ€æ±‚é€æ¼¸å¢žåŠ ã€‚è¨±å¤šå“¡å·¥å¸Œæœ›èƒ½å½ˆæ€§æ–¼å®¶è£¡å’Œè¾¦å…¬å®¤ä¹‹é–“åˆ‡æ›ï¼Œä»¥è¿½æ±‚æ›´å¥½çš„å·¥ä½œç”Ÿæ´»å¹³è¡¡ã€‚ã€

**è¼¸å‡º Slack å®£å‚³æ ¼å¼ï¼š**  
ðŸš€ **æ··åˆå¼å·¥ä½œä¾†å•¦ï¼é€™è£¡æœ‰ä½ ä¸èƒ½éŒ¯éŽçš„äº®é»žï¼š**  
ðŸ‘‰ ç–«æƒ…çµæŸå¾Œï¼Œæ··åˆå¼å·¥ä½œè¶Šä¾†è¶Šå—æ­¡è¿Žï¼  
ðŸ ðŸ’¼ å±…å®¶è¾¦å…¬å’Œè¾¦å…¬å®¤è‡ªç”±åˆ‡æ›ï¼Œå½ˆæ€§å·¥ä½œæ›´æ»¿è¶³ç”Ÿæ´»éœ€æ±‚ï¼  
ðŸŒŸ å“¡å·¥èªªï¼šé€™æ˜¯ä¿ƒé€²å·¥ä½œç”Ÿæ´»å¹³è¡¡çš„æœ€å¥½æ–¹å¼ä¹‹ä¸€ï½ž  
ðŸ‘‰ æƒ³æ›´å¤šäº†è§£æ··åˆå¼å·¥ä½œçš„å„ªå‹¢ï¼Ÿå¿«é»žæ“ŠðŸ‘‡  

ðŸ”— [äº†è§£æ›´å¤šè©³ç´°è³‡è¨Š]

*(å¯¦éš›æ¡ˆä¾‹æ‡‰æ›´ç²¾ç°¡ï¼Œå…·é«”åŒ–ï¼Œä¸¦æ·»åŠ æ–‡ç« çš„é“¾æŽ¥ç­‰ç´°ç¯€ï¼)*
    """
    prompt = PromptTemplate.from_template(prompt_template)

    chain = prompt | model
    tweet = chain.invoke(
        {"text": input_text})
    return tweet.content


def summarize_text(text: str, max_tokens: int = 100) -> str:
    '''
    Summarize a text using the Google Generative AI model.
    '''
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0,
        max_tokens=None,
        timeout=None,
        max_retries=2,
    )

    prompt_template = """ç”¨å°ç£ç”¨èªžçš„ç¹é«”ä¸­æ–‡ï¼Œç°¡æ½”åœ°ä»¥æ¢åˆ—å¼ç¸½çµæ–‡ç« é‡é»žã€‚åœ¨æ‘˜è¦å¾Œç›´æŽ¥åŠ å…¥ç›¸é—œçš„è‹±æ–‡ hashtagï¼Œä»¥ç©ºæ ¼åˆ†éš”ã€‚å…§å®¹ä¾†æºå¯ä»¥æ˜¯ç¶²é ã€æ–‡ç« ã€è«–æ–‡ã€å½±ç‰‡å­—å¹•æˆ–é€å­—ç¨¿ã€‚

    åŽŸæ–‡ï¼š "{text}"
    è«‹éµå¾ªä»¥ä¸‹æ­¥é©Ÿä¾†å®Œæˆæ­¤ä»»å‹™ï¼š

    # æ­¥é©Ÿ
    1. å¾žæä¾›çš„å…§å®¹ä¸­æå–é‡è¦é‡é»žï¼Œç„¡è«–ä¾†æºæ˜¯ç¶²é ã€æ–‡ç« ã€è«–æ–‡ã€å½±ç‰‡å­—å¹•æˆ–é€å­—ç¨¿ã€‚
    2. å°‡é‡é»žæ•´ç†æˆæ¢åˆ—å¼ï¼Œç¢ºä¿æ¯ä¸€é»žç‚ºç°¡çŸ­ä¸”æ˜Žç¢ºçš„å¥å­ã€‚
    3. ä½¿ç”¨ç¬¦åˆå°ç£ç”¨èªžçš„ç°¡æ½”ç¹é«”ä¸­æ–‡ã€‚
    4. åœ¨æ‘˜è¦çµå°¾è™•ï¼ŒåŠ å…¥è‡³å°‘ä¸‰å€‹ç›¸é—œçš„è‹±æ–‡ hashtagï¼Œä¸¦ä»¥ç©ºæ ¼åˆ†éš”ã€‚

    # è¼¸å‡ºæ ¼å¼
    - é‡é»žæ‡‰ä»¥æ¢åˆ—å¼åˆ—å‡ºï¼Œæ¯ä¸€é»žæ‡‰ç‚ºä¸€å€‹çŸ­å¥æˆ–ç‰‡èªžï¼Œèªžè¨€å¿…é ˆç°¡æ½”æ˜Žçž­ã€‚
    - æœ€å¾ŒåŠ å…¥è‡³å°‘ä¸‰å€‹ç›¸é—œçš„è‹±æ–‡ hashtagï¼Œæ¯å€‹ hashtag ä¹‹é–“ç”¨ç©ºæ ¼åˆ†éš”ã€‚

    # ç¯„ä¾‹
    è¼¸å…¥ï¼š
    æ–‡ç« å…§å®¹ï¼š
    å°ç£çš„å ±å‘ŠæŒ‡å‡ºï¼Œç’°å¢ƒä¿è­·çš„é‡è¦æ€§æ—¥ç›Šå¢žåŠ ã€‚è¨±å¤šäººé–‹å§‹é¸æ“‡ä½¿ç”¨å¯é‡è¤‡ä½¿ç”¨çš„ç”¢å“ã€‚æ”¿åºœä¹Ÿå¯¦æ–½äº†å¤šé …æ”¿ç­–ä¾†é™ä½Žå»¢ç‰©ã€‚

    æ‘˜è¦ï¼š

    è¼¸å‡ºï¼š
    - ç’°å¢ƒä¿è­·é‡è¦æ€§å¢žåŠ 
    - è¶Šä¾†è¶Šå¤šäººä½¿ç”¨å¯é‡è¤‡ç”¢å“
    - æ”¿åºœå¯¦æ–½æ¸›å»¢æ”¿ç­–
    #EnvironmentalProtection #Sustainability #Taiwan
    """

    prompt = PromptTemplate.from_template(prompt_template)

    summarize_chain = load_summarize_chain(
        llm=llm, chain_type="stuff", prompt=prompt)
    document = Document(page_content=text)
    summary = summarize_chain.invoke([document])
    return summary["output_text"]


def generate_json_from_image(img: PIL.Image.Image, prompt: str) -> Any:
    model = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0.5,
        max_tokens=None,
        timeout=None,
        max_retries=2,
    )

    prompt_template = PromptTemplate.from_template(prompt)
    chain = prompt_template | model
    response = chain.invoke({"image": img})

    try:
        if response.parts:
            logging.info(f">>>>{response.text}")
            return response
        else:
            logging.warning("No valid parts found in the response.")
            for candidate in response.candidates:
                logging.warning("!!!!Safety Ratings:",
                                candidate.safety_ratings)
    except ValueError as e:
        logging.error("Error:", e)
    return response
